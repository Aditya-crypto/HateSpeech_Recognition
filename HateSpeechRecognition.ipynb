{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpeechRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tBS4ypy7_t4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiBBX86s6S3g",
        "colab_type": "code",
        "outputId": "21fc9705-7a18-42f2-9237-da0a7e95d13d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "!pip install emot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emot\n",
            "  Downloading https://files.pythonhosted.org/packages/49/07/20001ade19873de611b7b66a4d5e5aabbf190d65abea337d5deeaa2bc3de/emot-2.1-py3-none-any.whl\n",
            "Installing collected packages: emot\n",
            "Successfully installed emot-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfW0xRw96Olm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from emot.emo_unicode import UNICODE_EMO, EMOTICONS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbHxo_7q-YGt",
        "colab_type": "text"
      },
      "source": [
        "## Reading train and test files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN3xIFPG8MPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/My Drive/assign5_dataset/train.csv\")\n",
        "# print(df)\n",
        "test=pd.read_csv(\"/content/drive/My Drive/assign5_dataset/test.csv\")\n",
        "# print(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKKOCHto8zsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=df['labels']\n",
        "# print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnTh7PIRp1IW",
        "colab_type": "code",
        "outputId": "4b09997d-9522-42c5-8868-ca7a749545bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "print(df['text'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       @realDonaldTrump This is one of the worst time...\n",
            "1       How about the crowd in Oval in today's #AUSvIN...\n",
            "2       @skroskz @shossy2 @JoeBiden Biden &amp; his so...\n",
            "3       #etsy shop: Benedict Donald so called presiden...\n",
            "4       @realDonaldTrump Good build a wall around Arka...\n",
            "                              ...                        \n",
            "5261    @ICC should allow ms dhoni to keep glove. It i...\n",
            "5262    Trump on avoiding movie pirating: 'of course y...\n",
            "5263    I noticed recently Jamie Oliver's restaurants ...\n",
            "5264    #TeamIndia geared up is okay. What's on the GL...\n",
            "5265    Is this the same piece of paper McCarthy used ...\n",
            "Name: text, Length: 5266, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LQXsgUG-jqQ",
        "colab_type": "text"
      },
      "source": [
        "## For breaking hashtags in meaningful words(Using Wordninja)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZgbdgcCzO_1",
        "colab_type": "code",
        "outputId": "5cdbbcaa-a310-4f43-aea0-eebe91dd39a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!pip install wordninja"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wordninja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/15/abe4af50f4be92b60c25e43c1c64d08453b51e46c32981d80b3aebec0260/wordninja-2.0.0.tar.gz (541kB)\n",
            "\r\u001b[K     |▋                               | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 6.5MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 7.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40kB 7.8MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 102kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 112kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 204kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 225kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 245kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 296kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 317kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 358kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 378kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 409kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 430kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 450kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 471kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 481kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 491kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 501kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 512kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 522kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 542kB 8.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordninja\n",
            "  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordninja: filename=wordninja-2.0.0-cp36-none-any.whl size=541552 sha256=74a589a9e17d55b87f426897e027f571ddfcb57923db8ce19b38c2d3b440cd17\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/46/06/9b6d10ed02c85e93c3bb33ac50e2d368b2586248f192a2e22a\n",
            "Successfully built wordninja\n",
            "Installing collected packages: wordninja\n",
            "Successfully installed wordninja-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6ekdDLJzGNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wordninja as wn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA0fVSS-4Bu1",
        "colab_type": "code",
        "outputId": "e2aa1add-9c7d-40ac-e91f-b875ff759323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX0z2eL2-ftw",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DenPxr3KHAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting emojis to text\n",
        "#https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing\n",
        "\n",
        "def convert_emojis(text):\n",
        "    for emot in UNICODE_EMO:\n",
        "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
        "    return text\n",
        "def remove_numbers(text): \n",
        "    result = re.sub(r'\\d+', '', text) \n",
        "    return result\n",
        "\n",
        "PUNCT_TO_REMOVE = string.punctuation\n",
        "def remove_punctuation(text):\n",
        "    \"\"\"custom function to remove the punctuation\"\"\"\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "def stem_words(text):\n",
        "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_words(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "def clean_text(text):\n",
        "  text=text.lower()\n",
        "    \n",
        "  # text=re.sub(r'[\"|\\'|?|,)|(|-]',r'',text)\n",
        "  text=\" \".join(filter(lambda x:x[0]!='@', text.split()))\n",
        "  text=remove_punctuation(text)\n",
        "  text=re.sub(r\"http\\S+\", \"\",text)\n",
        "  text=lemmatize_words(text)\n",
        "  text=remove_numbers(text)\n",
        "  text=stem_words(text)\n",
        "  \n",
        "  # text=convert_emojis(text)\n",
        "  # # # breaking #tags in comments to meaningful words\n",
        "  \n",
        "  # text=wn.split(text)\n",
        "\n",
        "  \n",
        "  return text\n",
        "\n",
        "round1= lambda x: clean_text(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qWYMSL1DHUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tempdata=df.text.apply(round1)\n",
        "clean_data=pd.DataFrame(tempdata)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czbSyZOlptsG",
        "colab_type": "code",
        "outputId": "8c499cd3-6bdf-465d-ee73-b9d700996887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(clean_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   text\n",
            "0     thi is one of the worst time to be american be...\n",
            "1     how about the crowd in oval in today ausvind h...\n",
            "2     biden amp hi son hunter took advantag of their...\n",
            "3     etsi shop benedict donald so call presid is a ...\n",
            "4     good build a wall around arkansa fucktrump fuc...\n",
            "...                                                 ...\n",
            "5261  should allow m dhoni to keep glove it is attac...\n",
            "5262  trump on avoid movi pirat of cours you have to...\n",
            "5263  i notic recent jami oliv restaur closingi onli...\n",
            "5264  teamindia gear up is okay what on the glove ar...\n",
            "5265  is thi the same piec of paper mccarthi use to ...\n",
            "\n",
            "[5266 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEQ-CYsb_LHj",
        "colab_type": "text"
      },
      "source": [
        "# Different Methods of converting text to vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3bu-s3G_otN",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP5wJcV3XFbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dummy_fun(doc):\n",
        "    return doc\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    # analyzer='word',\n",
        "    # tokenizer=dummy_fun,\n",
        "    # preprocessor=dummy_fun,\n",
        "    stop_words='english')\n",
        "    # token_pattern=None)  \n",
        "\n",
        "data_cv1=tfidf.fit_transform(clean_data['text'])\n",
        "dataset=pd.DataFrame(data_cv1.toarray(),columns=tfidf.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn-HdIcEV145",
        "colab_type": "code",
        "outputId": "85059b1b-c4ac-48d6-eb63-bad9cc74dded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      aaaaarrrrrggggghhhhh  aadmi  aag  aaj  ...  𝙜𝙧𝙤𝙪𝙣𝙙  𝙨𝙖𝙡𝙪𝙩𝙚  𝙩𝙚𝙖𝙢   𝙩𝙤\n",
            "0                      0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "1                      0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "2                      0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "3                      0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "4                      0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "...                    ...    ...  ...  ...  ...     ...     ...   ...  ...\n",
            "5261                   0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "5262                   0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "5263                   0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "5264                   0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "5265                   0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "\n",
            "[5266 rows x 11026 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiSXYXRqLfgq",
        "colab_type": "code",
        "outputId": "5d3e33d3-0535-4000-b583-e44f2e776322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "Finaltest=pd.read_csv(\"/content/drive/My Drive/assign5_dataset/f_test.csv\")\n",
        "print(Finaltest.columns)\n",
        "print(Finaltest['Unnamed: 0'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'text_id', 'text'], dtype='object')\n",
            "0          0\n",
            "1          1\n",
            "2          2\n",
            "3          3\n",
            "4          4\n",
            "        ... \n",
            "1148    1148\n",
            "1149    1149\n",
            "1150    1150\n",
            "1151    1151\n",
            "1152    1152\n",
            "Name: Unnamed: 0, Length: 1153, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUMzHR5Dct-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Finaltest=pd.read_csv(\"/content/drive/My Drive/assign5_dataset/f_test.csv\")\n",
        "clean_test_data=pd.DataFrame(Finaltest.text.apply(round1))\n",
        "data_cv1=tfidf.transform(clean_test_data.text)\n",
        "Finaltestdata=pd.DataFrame(data_cv1.toarray(),columns=tfidf.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA8t6t1Hc01d",
        "colab_type": "code",
        "outputId": "4880822e-1d2c-4b9c-d17a-6c88b133b4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(Finaltestdata)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      aaaaarrrrrggggghhhhh  aadmi  aag  aaj  ...  𝙜𝙧𝙤𝙪𝙣𝙙  𝙨𝙖𝙡𝙪𝙩𝙚  𝙩𝙚𝙖𝙢   𝙩𝙤\n",
            "0                      0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "1                      0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "2                      0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "3                      0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "4                      0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "...                    ...    ...  ...  ...  ...     ...     ...   ...  ...\n",
            "1148                   0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "1149                   0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "1150                   0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "1151                   0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "1152                   0.0    0.0  0.0  0.0  ...     0.0     0.0   0.0  0.0\n",
            "\n",
            "[1153 rows x 11040 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyzOnCiSNY_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting testdata using TFIDF\n",
        "clean_test_data=pd.DataFrame(test.text.apply(round1))\n",
        "data_cv1=tfidf.transform(clean_test_data.text)\n",
        "test_dataset=pd.DataFrame(data_cv1.toarray(),columns=tfidf.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEDu1LRrL3VZ",
        "colab_type": "code",
        "outputId": "29b0185e-beea-4d70-a1f7-fa601653474b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     001   01   02   03   04   05  ...  𝙘𝙧𝙞𝙘𝙠𝙚𝙩  𝙛𝙧𝙤𝙢  𝙜𝙧𝙤𝙪𝙣𝙙  𝙨𝙖𝙡𝙪𝙩𝙚  𝙩𝙚𝙖𝙢   𝙩𝙤\n",
            "0    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0     0.0     0.0   0.0  0.0\n",
            "1    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0     0.0     0.0   0.0  0.0\n",
            "2    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0     0.0     0.0   0.0  0.0\n",
            "3    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0     0.0     0.0   0.0  0.0\n",
            "4    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0     0.0     0.0   0.0  0.0\n",
            "..   ...  ...  ...  ...  ...  ...  ...      ...   ...     ...     ...   ...  ...\n",
            "581  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0     0.0     0.0   0.0  0.0\n",
            "582  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0     0.0     0.0   0.0  0.0\n",
            "583  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0     0.0     0.0   0.0  0.0\n",
            "584  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0     0.0     0.0   0.0  0.0\n",
            "585  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0     0.0     0.0   0.0  0.0\n",
            "\n",
            "[586 rows x 11486 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Xt0LM7_8N0",
        "colab_type": "text"
      },
      "source": [
        "## Word2vec Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbCBBAM_PKKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Word2Vec(textData,window=5,size=100,min_count=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uLgKsYrTB9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer=TfidfVectorizer()\n",
        "vectors=vectorizer.fit_transform(df['text'])\n",
        "TF_dataset = vectors.todense()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qweq0gkXAPoM",
        "colab_type": "text"
      },
      "source": [
        "### Average Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LECnNuLeR3H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#avg word2vec\n",
        "def convToVec(model,textData):\n",
        "  review_vec=[]\n",
        "  for line in textData:\n",
        "    rvec=np.zeros(100)\n",
        "    cnt=0\n",
        "    for w in line:\n",
        "      try:\n",
        "        vec=model.wv[w]\n",
        "        rvec+=vec\n",
        "        cnt+=1\n",
        "      except:\n",
        "        pass\n",
        "    rvec/=cnt\n",
        "    review_vec.append(rvec)\n",
        "  print(len(review_vec))\n",
        "  print(review_vec[0])\n",
        "  return review_vec\n",
        "#tfidf word2vec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "168lllFVAXgP",
        "colab_type": "text"
      },
      "source": [
        "### TF-IDF Form of Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOFNmKI1uw5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features=vectorizer.get_feature_names()\n",
        "def convTotfVec(model,textData):\n",
        "  review_vec_tf=[]\n",
        "  row=0\n",
        "  for line in textData:\n",
        "    rvec_tf=np.zeros(100)\n",
        "    weight_sum=0\n",
        "    for w in line:\n",
        "      try:\n",
        "        vec=model.wv[w]\n",
        "        tfidf=finaltfidf(row,features.index[w])\n",
        "        rvec_tf+=(vec*tfidf)\n",
        "        weight_sum+=tfidf\n",
        "      except:\n",
        "        pass\n",
        "    rvec_tf/=weight_sum\n",
        "    review_vec_tf.append(rvec_tf)\n",
        "    row+=1\n",
        "  print(len(review_vec_tf))\n",
        "  print(review_vec_tf[0])\n",
        "  return review_vec_tf\n",
        "AVG_dataset=np.asarray(convToVec(model,textData))\n",
        "TFW_dataset=np.asarray(convTotfVec(model,textData))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWsx1Gw3n4IE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "dataset=StandardScaler().fit_transform(dataset)\n",
        "AVG_dataset=np.nan_to_num(AVG_dataset)\n",
        "TFW_dataset=np.nan_to_num(TFW_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDO8brNoV8oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWkXCpD6axjl",
        "colab_type": "text"
      },
      "source": [
        "## Training Models using TFIDF Dataform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYU2sfuEA1Hb",
        "colab_type": "text"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFVDcO2BA44M",
        "colab_type": "text"
      },
      "source": [
        "#### SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YxT_8eR_HvF",
        "colab_type": "text"
      },
      "source": [
        "## Using GridSearchCV for fine tuning different parameters of SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXS-Lby8Nxro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHx3__rGN241",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = {'C': [0.1], 'gamma': [1,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
        "# param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjKJ6Geg_UPd",
        "colab_type": "text"
      },
      "source": [
        "## Splitting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6isHGraVKnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset,labels, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3tIe1ARa6TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb3c1sYGkuS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY4k3REROkK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape)\n",
        "print(test_dataset.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWdwrrhK_blt",
        "colab_type": "text"
      },
      "source": [
        "## Applying GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ZrgufAAJ_r",
        "colab_type": "code",
        "outputId": "77a77b0f-c3dd-412c-d394-fa41b2617c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2,n_jobs=-1)\n",
        "grid.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'C': [0.1], 'gamma': [1, 0.001],\n",
              "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntlxctEjOpLc",
        "colab_type": "code",
        "outputId": "7899b02f-fdb9-4d9b-cbbd-c5cd571153a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(grid.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
            "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o65-DBu6QHX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Svmlabels = grid.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9zWYRW2_gn8",
        "colab_type": "text"
      },
      "source": [
        "## SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4snFbvGoZ_ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SVMmodel=svm.SVC(kernel='rbf')\n",
        "SVMmodel.fit(X_train,y_train)\n",
        "SVMlabels = SVMmodel.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-hZFzGPH59x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(SVMlabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbRY_k03OQCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predlabels = SVMmodel.predict(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgbUaet6dUc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finalpredlabels = SVMmodel.predict(Finaltestdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-kmCdZRvefX",
        "colab_type": "code",
        "outputId": "938c7a74-0f5c-4876-c2b9-f550fe337b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(SVMlabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYH2atCoxGgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt('submission.csv', predlabels, delimiter=' ', header='labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11gxi0KPd8Pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt('submission.csv', finalpredlabels, delimiter=' ', header='labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wylFNGffRYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_file(predictLabels,testdata):\n",
        "  smiles=testdata['Unnamed: 0'] \n",
        "  list_of_tuples = list(zip(smiles, predictLabels))  \n",
        "  sub = pd.DataFrame(list_of_tuples, columns = [' ', 'labels'])   \n",
        "  print(sub)\n",
        "  sub.to_csv('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oETtAuPofxiw",
        "colab_type": "code",
        "outputId": "9ab8a2a3-a57a-44fd-f618-43620aa58858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "create_file(finalpredlabels,Finaltest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            labels\n",
            "0        0       1\n",
            "1        1       1\n",
            "2        2       1\n",
            "3        3       1\n",
            "4        4       0\n",
            "...    ...     ...\n",
            "1148  1148       1\n",
            "1149  1149       1\n",
            "1150  1150       1\n",
            "1151  1151       1\n",
            "1152  1152       1\n",
            "\n",
            "[1153 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkqnDZQHatRo",
        "colab_type": "code",
        "outputId": "5c128fb8-b9ff-43f6-ef25-1782942402c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,SVMlabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6698292220113852"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMQm1JdYhDT1",
        "colab_type": "code",
        "outputId": "6baa0ea1-6f84-42fd-b9f6-7d60c72c3500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, SVMlabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7774936061381074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wELCZJL-N1Dn",
        "colab_type": "text"
      },
      "source": [
        "#### LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLRonFJXU9sF",
        "colab_type": "code",
        "outputId": "97563675-70da-4732-acda-eef6f839e501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# tunned_param=[{'C':[.000241,.000257,.0004,.0005,.0006,.007]}]\n",
        "# LRmodel=GridSearchCV(LogisticRegression(max_iter=1000),tunned_param,scoring='accuracy')\n",
        "LRmodel=LogisticRegression()\n",
        "LRmodel.fit(X_train,y_train)\n",
        "LRlabels=LRmodel.predict(X_test)\n",
        "# print(LRlabels)\n",
        "# print(LRmodel.best_estimator_)\n",
        "print(LRmodel.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6907020872865275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsKzw31nbXk-",
        "colab_type": "code",
        "outputId": "c8787a79-cb46-4971-8999-87f75787bf7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, LRlabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.788036410923277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-3W5m0xNwCE",
        "colab_type": "text"
      },
      "source": [
        "#### MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRFfnIkZnOuW",
        "colab_type": "code",
        "outputId": "6ad511bf-2695-4897-afe2-c43204e9424c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import optimizers\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNPKVgPOOOsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytrain = keras.utils.to_categorical(y_train,2)\n",
        "ytest = keras.utils.to_categorical(y_test,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihr04fx9bRYb",
        "colab_type": "code",
        "outputId": "cfaa30fd-db62-4b49-b131-c538b4ad61e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(dataset.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5266, 11486)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zToRaLhOoXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=5,activation=\"relu\",input_shape=(11486,)))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(units=6,activation=\"relu\"))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(units=2,activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNYkZNFROpdm",
        "colab_type": "code",
        "outputId": "a79578ea-e7dc-457e-fdaa-2498b3b385de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "history=model.fit(X_train,ytrain,batch_size=64,epochs=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.6790 - accuracy: 0.6103\n",
            "Epoch 2/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.6518 - accuracy: 0.6111\n",
            "Epoch 3/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.5962 - accuracy: 0.6590\n",
            "Epoch 4/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.4942 - accuracy: 0.8164\n",
            "Epoch 5/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.3847 - accuracy: 0.8810\n",
            "Epoch 6/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.2967 - accuracy: 0.9105\n",
            "Epoch 7/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.2296 - accuracy: 0.9340\n",
            "Epoch 8/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.1793 - accuracy: 0.9510\n",
            "Epoch 9/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.1465 - accuracy: 0.9610\n",
            "Epoch 10/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.1211 - accuracy: 0.9677\n",
            "Epoch 11/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.1043 - accuracy: 0.9715\n",
            "Epoch 12/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0898 - accuracy: 0.9738\n",
            "Epoch 13/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0788 - accuracy: 0.9778\n",
            "Epoch 14/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0691 - accuracy: 0.9795\n",
            "Epoch 15/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0690 - accuracy: 0.9804\n",
            "Epoch 16/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0582 - accuracy: 0.9816\n",
            "Epoch 17/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0514 - accuracy: 0.9846\n",
            "Epoch 18/30\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0473 - accuracy: 0.9848\n",
            "Epoch 19/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0435 - accuracy: 0.9857\n",
            "Epoch 20/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0400 - accuracy: 0.9859\n",
            "Epoch 21/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0378 - accuracy: 0.9867\n",
            "Epoch 22/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0359 - accuracy: 0.9876\n",
            "Epoch 23/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0331 - accuracy: 0.9878\n",
            "Epoch 24/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0325 - accuracy: 0.9876\n",
            "Epoch 25/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0309 - accuracy: 0.9880\n",
            "Epoch 26/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0299 - accuracy: 0.9878\n",
            "Epoch 27/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0286 - accuracy: 0.9876\n",
            "Epoch 28/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0277 - accuracy: 0.9890\n",
            "Epoch 29/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0286 - accuracy: 0.9859\n",
            "Epoch 30/30\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0271 - accuracy: 0.9888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdbrqWWBXaft",
        "colab_type": "code",
        "outputId": "bbf3a02e-a294-434a-ebbd-c840eef45d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score=model.evaluate(X_test,ytest,verbose = 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17/17 - 0s - loss: 1.7666 - accuracy: 0.6186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djh1loMOcVfN",
        "colab_type": "code",
        "outputId": "37c0972f-d6ef-48c5-ad51-d35093f74ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6185958385467529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YZdRMR8XnBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "#Converting predictions to label\n",
        "MLPlabels = list()\n",
        "for i in range(len(y_pred)):\n",
        "    MLPlabels.append(np.argmax(y_pred[i]))\n",
        "#Converting one hot encoded test label to label\n",
        "test = list()\n",
        "for i in range(len(ytest)):\n",
        "    test.append(np.argmax(ytest[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLH7T0QoJsdc",
        "colab_type": "code",
        "outputId": "8e797790-c896-4985-f4c7-d71241dd273d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(MLPlabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bFafuncdDxD",
        "colab_type": "code",
        "outputId": "47382b7a-fce6-479a-c350-dac9079ae9c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "a =f1_score(MLPlabels,test)\n",
        "print('Accuracy is:', a*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 68.26706676669167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBBd9PupiEju",
        "colab_type": "text"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvNmthl8iUeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import LSTM\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_VGHOIRlGc4",
        "colab_type": "code",
        "outputId": "d5847a78-b277-43ea-c202-9699c2d94daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "t = Tokenizer(nb_words=5500,lower=True,split=' ')\n",
        "t.fit_on_texts(clean_data['text'].values)\n",
        "# print(t.word_counts)\n",
        "# print(t.document_count)\n",
        "# print(t.word_index)\n",
        "# print(t.word_docs)\n",
        "X = t.texts_to_sequences(clean_data['text'])\n",
        "X = pad_sequences(X)\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(5266, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UsBkhjSvop1",
        "colab_type": "code",
        "outputId": "e3de3b2a-a1a7-40fe-9f04-e1bccaa87633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(X[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0   62   50\n",
            "    1 1408    8 1409    8  148 1036  484  495  350 3040 1302   22  122\n",
            "  571   28]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fsKygnYYhNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.layers import Dense, Dropout, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuzJYeWiiNC-",
        "colab_type": "code",
        "outputId": "7a4c29c0-877f-477f-ef92-ca77d43ecfa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "embed_dim = 128\n",
        "batch_size = 32\n",
        "\n",
        "LSTMmodel = Sequential()\n",
        "LSTMmodel.add(Embedding(5500, embed_dim,input_length = X.shape[1]))\n",
        "LSTMmodel.add(Dropout(0.2))\n",
        "# LSTMmodel.add(LSTM(15,recurrent_dropout=0.2,input_shape=(1,10908)))\n",
        "LSTMmodel.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "LSTMmodel.add(MaxPooling1D(pool_size=2))\n",
        "LSTMmodel.add(LSTM(15, dropout=0.2, recurrent_dropout=0.2))\n",
        "LSTMmodel.add(Dropout(0.5))\n",
        "# LSTMmodel.add(Dense(40,activation='relu'))\n",
        "LSTMmodel.add(Dense(64,activation='relu'))\n",
        "LSTMmodel.add(Dropout(0.3))\n",
        "LSTMmodel.add(Dense(32,activation='relu'))\n",
        "LSTMmodel.add(Dense(16,activation='relu'))\n",
        "LSTMmodel.add(Dropout(0.3))\n",
        "LSTMmodel.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "LSTMmodel.compile(loss = 'binary_crossentropy', optimizer='adadelta',metrics = ['accuracy'])\n",
        "print(LSTMmodel.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 58, 128)           704000    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 58, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 58, 32)            12320     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 29, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 15)                2880      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                1024      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 722,849\n",
            "Trainable params: 722,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fxezolpirdQ",
        "colab_type": "code",
        "outputId": "4480f5f9-0023-4599-e864-b87326284c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train, X_test, Y_train, Y_valid = train_test_split(X,labels,test_size = 0.20)\n",
        "# x_train=np.array(X_train)\n",
        "# trainX= np.reshape(x_train,(x_train.shape[0], 1, x_train.shape[1]))\n",
        "LSTMmodel.fit(X_train, Y_train, batch_size =batch_size, nb_epoch = 50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4212/4212 [==============================] - 7s 2ms/step - loss: 0.6727 - accuracy: 0.6109\n",
            "Epoch 2/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.6661 - accuracy: 0.6125\n",
            "Epoch 3/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.6531 - accuracy: 0.6135\n",
            "Epoch 4/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.6323 - accuracy: 0.6439\n",
            "Epoch 5/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.6028 - accuracy: 0.6880\n",
            "Epoch 6/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.5610 - accuracy: 0.7241\n",
            "Epoch 7/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.5146 - accuracy: 0.7692\n",
            "Epoch 8/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.4699 - accuracy: 0.7915\n",
            "Epoch 9/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.4332 - accuracy: 0.8210\n",
            "Epoch 10/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.3774 - accuracy: 0.8497\n",
            "Epoch 11/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.3422 - accuracy: 0.8644\n",
            "Epoch 12/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.2956 - accuracy: 0.8910\n",
            "Epoch 13/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.2681 - accuracy: 0.9084\n",
            "Epoch 14/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.2361 - accuracy: 0.9202\n",
            "Epoch 15/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.2173 - accuracy: 0.9292\n",
            "Epoch 16/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.1898 - accuracy: 0.9399\n",
            "Epoch 17/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.1570 - accuracy: 0.9556\n",
            "Epoch 18/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.1456 - accuracy: 0.9561\n",
            "Epoch 19/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.1320 - accuracy: 0.9585\n",
            "Epoch 20/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.1157 - accuracy: 0.9656\n",
            "Epoch 21/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.1202 - accuracy: 0.9679\n",
            "Epoch 22/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.1099 - accuracy: 0.9694\n",
            "Epoch 23/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.1046 - accuracy: 0.9708\n",
            "Epoch 24/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0902 - accuracy: 0.9765\n",
            "Epoch 25/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0881 - accuracy: 0.9748\n",
            "Epoch 26/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0824 - accuracy: 0.9793\n",
            "Epoch 27/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0685 - accuracy: 0.9803\n",
            "Epoch 28/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0702 - accuracy: 0.9812\n",
            "Epoch 29/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0729 - accuracy: 0.9784\n",
            "Epoch 30/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0590 - accuracy: 0.9846\n",
            "Epoch 31/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0584 - accuracy: 0.9843\n",
            "Epoch 32/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0686 - accuracy: 0.9810\n",
            "Epoch 33/50\n",
            "4212/4212 [==============================] - 7s 2ms/step - loss: 0.0528 - accuracy: 0.9872\n",
            "Epoch 34/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0574 - accuracy: 0.9860\n",
            "Epoch 35/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0583 - accuracy: 0.9850\n",
            "Epoch 36/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0535 - accuracy: 0.9855\n",
            "Epoch 37/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0518 - accuracy: 0.9855\n",
            "Epoch 38/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0511 - accuracy: 0.9865\n",
            "Epoch 39/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0630 - accuracy: 0.9824\n",
            "Epoch 40/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0477 - accuracy: 0.9865\n",
            "Epoch 41/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0526 - accuracy: 0.9858\n",
            "Epoch 42/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0560 - accuracy: 0.9841\n",
            "Epoch 43/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0505 - accuracy: 0.9853\n",
            "Epoch 44/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0478 - accuracy: 0.9874\n",
            "Epoch 45/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0498 - accuracy: 0.9867\n",
            "Epoch 46/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0504 - accuracy: 0.9874\n",
            "Epoch 47/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0530 - accuracy: 0.9865\n",
            "Epoch 48/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0433 - accuracy: 0.9874\n",
            "Epoch 49/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0528 - accuracy: 0.9850\n",
            "Epoch 50/50\n",
            "4212/4212 [==============================] - 6s 1ms/step - loss: 0.0442 - accuracy: 0.9862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd978642400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7rvGha8iaFi",
        "colab_type": "code",
        "outputId": "61a5c6f3-750b-4135-910d-4e2df070c820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test=np.array(X_test)\n",
        "testX= np.reshape(x_test,(x_test.shape[0], 1, x_test.shape[1]))\n",
        "score=LSTMmodel.evaluate(X_test,Y_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1054/1054 [==============================] - 0s 379us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG33q7Y1ikg4",
        "colab_type": "code",
        "outputId": "578cd864-d7d8-42e1-df36-6d8b17fcfaeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6081593632698059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfozDsLMmo-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSTMlabels=LSTMmodel.predict(testX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAhgxY0zeK_N",
        "colab_type": "text"
      },
      "source": [
        "## random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2irgOe9eKT1",
        "colab_type": "code",
        "outputId": "2365b882-9fb0-468e-9d36-fe1575239d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4ol1VNbf85b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RFlabels=clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACd0SBiggEmp",
        "colab_type": "code",
        "outputId": "23750e4f-4d15-475c-ad8e-9660611c31ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "RFlabels=list(RFlabels)\n",
        "print(RFlabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNXSjLVv_1dO",
        "colab_type": "text"
      },
      "source": [
        "## combining all results using above trained models such as SVM, LR, MLP, LSTM, RF for Boosting method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tpc0eqPdYIo",
        "colab_type": "code",
        "outputId": "a217db10-63aa-47ad-e9d7-f49ecfeb2eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(type(LSTMlabels))\n",
        "print(type(SVMlabels))\n",
        "print(type(LRlabels))\n",
        "print(type(MLPlabels))\n",
        "def convert(predict_labels):\n",
        "  predicted=[]\n",
        "  for i in range(0,len(predict_labels)):\n",
        "    predicted.append(predict_labels[i][0])\n",
        "  return predicted\n",
        "LSTMlabel=convert(LSTMlabels)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uSHfPa7PeyL",
        "colab_type": "code",
        "outputId": "8d51c0fd-ec6f-4b98-979f-b8d3752bff7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# print(type(LSTMlabel))\n",
        "SVMlabel=list(SVMlabels)\n",
        "LRlabel=list(LRlabels)\n",
        "print(type(LSTMlabel))\n",
        "print(type(SVMlabel))\n",
        "print(type(LRlabel))\n",
        "print(type(MLPlabels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huzDiedsQVD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_list = [] \n",
        "for i in range(0, len(MLPlabels)): \n",
        "    res_list.append(int((round((MLPlabels[i] + SVMlabel[i]+LRlabel[i]+LSTMlabel[i]+RFlabels[i])/5))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGxUp5omQ1tj",
        "colab_type": "code",
        "outputId": "3110340d-910d-4c5d-f410-9f5806e94fd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(res_list))\n",
        "print(len(y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1054\n",
            "1054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEaHnO8UANP6",
        "colab_type": "text"
      },
      "source": [
        "## accuracy after applying Boosting method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSbZso_zSEu3",
        "colab_type": "code",
        "outputId": "30810c16-8d76-468c-d000-2ad368106be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "a =accuracy_score(res_list,y_test)\n",
        "b =f1_score(res_list,y_test)\n",
        "print('score is:', a*100)\n",
        "print('f1score is:', b*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score is: 64.51612903225806\n",
            "f1score is: 74.9665327978581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqhtbZQFoKJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SVMtestlabels=list(SVMmodel.predict(test_dataset))\n",
        "LRtestlabels=list(LRmodel.predict(test_dataset))\n",
        "MLPtestslabels=model.predict(test_dataset)\n",
        "MLPtestlabels = list()\n",
        "for i in range(len(MLPtestslabels)):\n",
        "   MLPtestlabels.append(np.argmax(MLPtestslabels[i]))\n",
        "x=np.array(test_dataset)\n",
        "X= np.reshape(x,(x.shape[0], 1, x.shape[1]))\n",
        "LSTMtestlabels=LSTMmodel.predict(X)\n",
        "LSTMtestlabel=convert(LSTMtestlabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9snS5b6qVU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RFtestslabels=list(clf.predict(test_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4GDzlEqfSFC",
        "colab_type": "code",
        "outputId": "018b12b6-da08-498f-def4-b564883e8b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "print(RFtestslabels)\n",
        "print(LSTMtestlabel)\n",
        "print(SVMtestlabels)\n",
        "print(LRtestlabels)\n",
        "print(MLPtestlabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1]\n",
            "[0.99990475, 1.6359093e-06, 0.99944127, 0.04145634, 0.7989781, 0.016355783, 0.9998156, 0.9969861, 0.9544617, 0.95954555, 0.99999803, 0.61763084, 0.09912807, 0.009566575, 0.99910045, 0.014242619, 0.008580178, 0.9311625, 0.007580161, 0.9751476, 0.020798445, 0.99945587, 0.004507631, 6.570536e-05, 0.9545127, 0.0044165254, 0.052199304, 0.17399159, 0.7413643, 0.9999931, 0.0036036372, 0.85206795, 5.663451e-06, 0.055921823, 5.3332715e-05, 0.98653805, 0.35993633, 0.36307937, 0.06378424, 0.0002950728, 0.69418406, 0.008389115, 0.9999156, 0.025339723, 0.99001455, 0.999997, 0.95781827, 0.0063156784, 0.9898952, 0.99860793, 0.11662641, 0.2891721, 0.77106214, 0.49980775, 0.99993104, 0.998611, 0.8648211, 0.9852351, 0.644681, 0.8783075, 0.6225288, 0.26952648, 0.9983354, 0.99985373, 0.99543834, 0.9334414, 1.0, 0.6728921, 0.9994866, 0.007392764, 0.001109153, 0.99992573, 0.014614046, 0.001539588, 0.9999682, 3.1519537e-06, 0.9533615, 0.03947887, 0.0015090704, 0.97938126, 0.50545555, 0.9980515, 0.00025439262, 0.0005007982, 0.22509772, 0.9999076, 0.9999969, 0.997246, 0.9474665, 0.84234834, 0.15523478, 0.99563825, 0.5415402, 0.9176848, 0.11770889, 0.0039633214, 0.0040411055, 0.9974241, 0.99907553, 0.20354736, 0.96896064, 0.065910876, 0.31151408, 0.48143548, 0.0027341843, 0.9896196, 0.019982666, 0.99998105, 0.9509456, 0.068989575, 0.90715706, 0.0001321435, 0.047139525, 9.818222e-05, 0.9991716, 0.0009351969, 0.8781806, 0.99999887, 0.16749689, 0.79677224, 0.4579115, 0.99574816, 0.47160533, 0.048077077, 0.0012949407, 8.793372e-05, 0.0030429661, 0.00590387, 0.00012737513, 0.017321914, 0.93175805, 0.99918365, 0.9990779, 0.07045707, 0.9999758, 0.58583945, 0.49849087, 1.0, 0.99961567, 0.5308083, 1.0, 0.00035753846, 0.9998531, 0.0023288727, 0.9989278, 0.8675906, 0.999882, 0.008749723, 0.4021362, 0.99995786, 0.743037, 0.02180934, 0.9859762, 0.99998176, 0.9845789, 0.9888642, 0.9999187, 0.28868958, 0.02831009, 0.96917075, 0.0036611557, 0.0004976392, 0.9816237, 0.44489953, 0.8969388, 0.9422915, 0.9985214, 0.9810908, 0.46082708, 0.010114491, 0.9997961, 0.99960196, 0.32436484, 0.012197703, 0.28928518, 0.0020833313, 0.99297285, 0.003148049, 0.9997494, 0.9981859, 0.0009768903, 0.009645909, 0.99699956, 0.9991554, 0.99958146, 0.22316152, 0.985768, 0.325646, 0.019981652, 0.9998776, 0.30579627, 0.013659865, 0.40487936, 0.99964887, 0.47372, 0.8678408, 0.67486316, 0.9506501, 0.95983875, 0.9972083, 0.0022510588, 0.8939923, 0.99905384, 0.9589076, 0.0020005107, 0.07709271, 0.9582318, 0.99998087, 0.96431375, 0.93683887, 0.9676211, 0.14507738, 0.99799216, 0.85406625, 0.0012573302, 0.9954077, 0.012908876, 0.005137503, 0.9829912, 0.79097974, 0.91907036, 0.0011957884, 0.99943864, 0.99944615, 8.584886e-06, 0.9999691, 0.00013655424, 0.9777318, 0.99984014, 0.29981035, 0.07632166, 0.99081755, 0.0033127964, 0.98032117, 0.08311376, 0.2920043, 0.9999771, 0.0043146014, 0.9984856, 0.0008327961, 0.735466, 0.020038873, 0.99999833, 0.95045584, 0.9997913, 0.9708384, 0.09092417, 0.02270034, 0.0026518404, 0.0009726286, 0.9985321, 0.99112606, 0.9999814, 0.39913356, 0.8054435, 0.016631275, 0.42217344, 0.0034612417, 0.4031478, 0.9991234, 0.8815441, 0.9597777, 0.12159702, 0.99979436, 0.9519752, 0.97834486, 0.041691452, 0.9999974, 0.9023253, 0.9910215, 0.99740374, 0.01012975, 0.9783727, 0.54947984, 0.0003337562, 0.6934761, 0.4177253, 0.97912264, 0.042536855, 0.7543191, 0.05344796, 0.013973892, 0.9999936, 0.09084588, 0.01983571, 0.006280601, 0.13869348, 0.0145484805, 0.98464453, 0.84010184, 0.2318795, 0.90444195, 0.0018474758, 0.9997319, 0.10778871, 0.92527115, 0.99998796, 0.0017535686, 0.0038470328, 0.75759614, 0.9997833, 0.78210366, 0.024304956, 0.1436893, 0.018572867, 0.6217638, 0.0042644143, 0.8288591, 0.9998086, 0.9925482, 0.9998988, 0.95316505, 0.17283621, 1.3356455e-05, 0.9846745, 0.9747863, 0.99594235, 0.10699931, 0.0008428991, 0.6153234, 0.021405786, 0.0019811094, 0.9998754, 0.9999916, 0.9996232, 7.000959e-05, 0.99970996, 0.00060912967, 0.99975586, 0.45741427, 0.9936516, 0.33052006, 0.0040991604, 0.009334743, 0.9961997, 0.020626843, 0.023515254, 0.036227673, 0.9845184, 0.99398136, 0.09485319, 0.99578416, 0.99705255, 0.027490646, 0.9918834, 0.07546389, 0.42420602, 0.99382657, 0.9992824, 0.0033881962, 0.009803057, 0.9332526, 0.45655477, 0.9723684, 0.98687315, 0.8268014, 0.9999569, 0.98887753, 0.0025059283, 0.041781425, 0.02130279, 0.999944, 0.8857861, 0.95985216, 0.008321643, 0.44638962, 0.9927482, 0.9963318, 0.9959415, 0.3862226, 0.99922, 0.15106681, 0.7577752, 0.0028436184, 0.6614438, 0.004505962, 0.19608063, 0.9965652, 0.7535212, 0.24604037, 0.99927115, 0.9999963, 0.9039403, 0.99962795, 0.0019186735, 0.99936336, 0.7675522, 0.99762726, 0.0038095415, 0.7237387, 0.85962, 0.99986887, 0.83905005, 0.0031250715, 0.049072713, 0.017668426, 0.9436052, 0.058830768, 0.9945686, 0.9990668, 0.9997983, 0.99999785, 0.79955167, 0.072730035, 0.0006017387, 8.73954e-05, 0.02010554, 0.99982643, 0.00036233664, 0.64799136, 0.01021868, 0.0063925087, 0.7196278, 0.96323824, 0.012150794, 0.9945562, 5.61532e-05, 0.9595149, 0.99830306, 0.9274869, 0.3124178, 0.9986727, 0.992162, 0.9977559, 0.9999497, 0.9397466, 0.009748876, 0.6720866, 0.9999956, 0.9993552, 0.5391593, 0.28405464, 0.9871983, 0.99597806, 0.92492837, 0.9999993, 0.85895145, 0.0068427324, 0.124356925, 0.99991727, 0.9933212, 0.99995613, 0.99964416, 0.98171103, 0.025468051, 0.0005351007, 1.0, 0.99527496, 0.004371375, 0.0015248656, 0.01392296, 0.98208094, 0.15767574, 0.999901, 0.00040900707, 0.999874, 0.68716013, 0.051060885, 0.00012403727, 0.9609522, 0.99657714, 7.436412e-06, 0.9997488, 0.9907378, 0.0002628863, 0.7017135, 0.9997931, 0.99991375, 0.99999917, 0.0048773587, 0.5687233, 3.5863955e-05, 0.56915957, 0.0040938854, 0.9990312, 0.014763087, 0.999874, 0.112929136, 0.9963702, 0.010074556, 0.9999919, 0.81954455, 0.0005361438, 0.98837936, 0.09459975, 0.99665534, 0.00057837367, 0.010935605, 0.9573027, 0.9758736, 0.82411945, 0.9999993, 0.15464762, 0.99450934, 2.8048806e-05, 0.008840412, 0.5991459, 0.9999988, 0.77965117, 0.024758339, 0.8974056, 0.9999403, 0.000456661, 0.13188896, 0.05152619, 0.00020495057, 0.00017139316, 0.9999963, 0.9997734, 0.0007752478, 0.004551202, 0.0013738275, 0.39222464, 0.9713178, 0.999999, 0.0011839867, 0.02429387, 0.48788974, 0.150902, 0.0016934872, 0.71878535, 0.9913193, 0.06593335, 0.9932506, 0.99242127, 0.9996232, 0.99923486, 0.99944127, 0.00055378675, 0.98667085, 0.9908351, 0.008291334, 0.98846257, 0.99992, 1.0, 0.9564146, 0.9976101, 0.9990171, 0.020672977, 0.5860873, 0.13248843, 0.02032417, 0.71341324, 0.00093114376, 0.9951174, 0.99907696, 0.9999966, 0.95378065, 0.98889077, 0.99851704, 0.9990363, 0.9999052, 0.83211875, 0.8979535, 0.99203897, 0.99999154, 0.8679991, 0.17911324, 0.0024539232, 0.0019418895, 0.035021394, 0.16443726, 0.0038365126, 0.9996731, 0.013975292, 0.0011853874, 0.10631004, 0.30583808, 0.9999865, 1.0, 1.0, 0.99994737, 0.0018402636, 0.9893229, 0.89787984, 0.9997745, 0.01568389, 0.70045793, 0.06725687, 0.9829873, 0.9999637, 0.99953085, 0.9984195, 0.06263003, 0.00068096275, 0.92146254]\n",
            "[1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
            "[1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1]\n",
            "[1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VpB9wROdR7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sublist = [] \n",
        "for i in range(0, len(MLPtestlabels)): \n",
        "    sublist.append(int((round((MLPtestlabels[i] + SVMtestlabels[i]+LRtestlabels[i]+LSTMtestlabel[i]+RFtestslabels[i])/5))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw5F4Il4eMQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt('submission.csv', sublist, delimiter=' ', header='labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8g3qiMyoQAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "a =f1_score(predict,Y_valid)\n",
        "print('score is:', a*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2hnLEvOcrFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}